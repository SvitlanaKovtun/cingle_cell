{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da30a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter notebook --NotebookApp.max_buffer_size=35536870912 \n",
    "# to run jupyter notebook using more available memory\n",
    "import os, gc, pickle, scipy.sparse, time, h5py, anndata, hdf5plugin#, lightgbm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "##feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "#from sklearn.svm import SVR takes way too long\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#import scanpy as sc\n",
    "import anndata\n",
    "import hdf5plugin\n",
    "from sys import getsizeof\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import h5py\n",
    "from scipy.sparse import csr_matrix\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "data_path = \"/home/skovtun/Single cell/Single_cell_data\"\n",
    "metadata = os.path.join(data_path,\"metadata.csv\")\n",
    "\n",
    "train_cite_inputs = os.path.join(data_path,\"train_cite_inputs.h5\")\n",
    "train_cite_targets = os.path.join(data_path,\"train_cite_targets.h5\")\n",
    "test_cite_inputs = os.path.join(data_path,\"test_cite_inputs.h5\")\n",
    "\n",
    "train_multi_inputs = os.path.join(data_path,\"train_multi_inputs.h5\")\n",
    "train_multi_targets = os.path.join(data_path,\"train_multi_targets.h5\")\n",
    "test_multi_inputs = os.path.join(data_path,\"test_multi_inputs.h5\")\n",
    "\n",
    "sample_submission = os.path.join(data_path,\"sample_submission.csv\")\n",
    "evaluation_ids = os.path.join(data_path,\"evaluation_ids.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf5f8bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading_dataa\n",
    "Xm_train = h5py.File(train_multi_inputs,'r')#, mode)\n",
    "target = h5py.File(train_multi_targets,'r')#, mode)\n",
    "metadata_df = pd.read_csv(metadata)\n",
    "mult = metadata_df[metadata_df['technology'] == 'multiome'].drop('technology', axis=1)\n",
    "Xm_test = h5py.File(test_multi_inputs, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21661765-4f9e-435a-b6cf-fa69b2dea597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000\n",
      "1000 2000\n",
      "2000 3000\n",
      "3000 4000\n",
      "4000 5000\n",
      "5000 6000\n",
      "6000 7000\n",
      "7000 8000\n",
      "8000 9000\n",
      "9000 10000\n",
      "10000 10500\n"
     ]
    }
   ],
   "source": [
    "# Open the h5py file\n",
    "with h5py.File(train_multi_inputs, 'r') as h5file:\n",
    "    # Access the dataset within the group\n",
    "    data = h5file['train_multi_inputs']['block0_values']\n",
    " \n",
    "    # Determine the total number of samples and features\n",
    "    total_samples, total_features = data.shape\n",
    "    \n",
    "    # Set the desired number of samples for the random sample\n",
    "    desired_samples = 10500  # Adjust as needed\n",
    "\n",
    "    # Randomly sample row indices\n",
    "    first_sample_indices = np.sort(np.random.choice(total_samples, size=desired_samples, replace=False))\n",
    "    # Generate indices for the remaining data\n",
    "    all_indices = np.arange(total_samples)\n",
    "    remaining_indices = np.setdiff1d(all_indices, first_sample_indices)\n",
    "\n",
    "    # Randomly sample 10000 indices from the remaining data\n",
    "    second_sample_indices = np.sort(np.random.choice(remaining_indices, size=desired_samples, replace=False))\n",
    "    data_list1 = []\n",
    "    indices_list1 = []\n",
    "    indptr_list1 = [0]  # Initialize with 0\n",
    "    data_list2 = []\n",
    "    indices_list2 = []\n",
    "    indptr_list2 = [0]  # Initialize with 0\n",
    "    \n",
    "    # Iterate over chunks of data to extract and process the sampled rows\n",
    "    chunk_size = 1000  # Adjust as needed\n",
    "    for start in range(0, desired_samples, chunk_size):\n",
    "        end = min(start + chunk_size, desired_samples)\n",
    "        print(start, end)\n",
    "        chunk1 = data[first_sample_indices[start:end]]\n",
    "        chunk2 = data[second_sample_indices[start:end]]\n",
    "        \n",
    "        # Process the chunk, convert to CSR format\n",
    "        processed_chunk_sparse1 = csr_matrix(chunk1)\n",
    "        processed_chunk_sparse2 = csr_matrix(chunk2)\n",
    "        \n",
    "        # Update indptr and store the data and indices\n",
    "        indptr_list1.extend(processed_chunk_sparse1.indptr[1:] + indptr_list1[-1])\n",
    "        data_list1.append(processed_chunk_sparse1.data)\n",
    "        indices_list1.append(processed_chunk_sparse1.indices)\n",
    "\n",
    "        # Update indptr and store the data and indices\n",
    "        indptr_list2.extend(processed_chunk_sparse2.indptr[1:] + indptr_list2[-1])\n",
    "        data_list2.append(processed_chunk_sparse2.data)\n",
    "        indices_list2.append(processed_chunk_sparse2.indices)\n",
    "    \n",
    "    # Combine the lists into arrays\n",
    "    values1 = np.concatenate(data_list1)\n",
    "    indices1 = np.concatenate(indices_list1)\n",
    "    indptr1 = np.array(indptr_list1)\n",
    "\n",
    "    # Combine the lists into arrays\n",
    "    values2 = np.concatenate(data_list2)\n",
    "    indices2 = np.concatenate(indices_list2)\n",
    "    indptr2 = np.array(indptr_list2)\n",
    "\n",
    "    # Create the final CSR sparse matrix\n",
    "    sampled_sparse_matrix1 = csr_matrix((values1, indices1, indptr1), shape=(desired_samples, total_features))\n",
    "    sampled_sparse_matrix2 = csr_matrix((values2, indices2, indptr2), shape=(desired_samples, total_features))\n",
    "\n",
    "#Save the sparse matrix using scipy's save_npz\n",
    "from scipy.sparse import save_npz\n",
    "save_npz('sampled_data1.npz', sampled_sparse_matrix1)\n",
    "save_npz('sampled_data2.npz', sampled_sparse_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86322ae-e83f-4132-bd8c-38310a6b95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_sparse_matrix1 = scipy.sparse.load_npz('sampled_data1.npz')\n",
    "sampled_sparse_matrix2 = scipy.sparse.load_npz('sampled_data2.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "396902d3-582d-4e32-ac99-0d603a4c48cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70477057\n",
      "--- 2730.798979997635 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Originas TruncatedSVD\n",
    "#Trying to figure out how much features we have to leave after reduction\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "start_time = time.time()\n",
    "svd = TruncatedSVD(n_components=6000, n_iter=7, random_state=42)\n",
    "svd.fit(sampled_sparse_matrix)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "print(f\"--- {time.time() - start_time} seconds ---\")\n",
    "# 3000 explained 0.4 variance and worked 1206.3879735469818 seconds\n",
    "# 6000 explained 0.7 variance and worked 2719 seconds\n",
    "# 8000 explained 0.8609857 variance worked 3876.7784655094147 seconds\n",
    "# 9000 explained 0.9259014 variance 4494.362522602081 vs 29067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a64ff580-e1d6-45c1-9308-d54589291b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save and load SVD model\n",
    "# Save the SVD model using joblib\n",
    "#joblib.dump(svd, 'svd_model_10500_6000.joblib')\n",
    "\n",
    "# Later, to load and use the SVD model\n",
    "loaded_svd_pipeline = joblib.load('svd_model_10500_6000.joblib')\n",
    "\n",
    "# Transform new datasets using the loaded SVD model\n",
    "# transformed_data = loaded_svd_pipeline.transform(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3af3066-ab13-412e-822c-285e737ccd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = loaded_svd_pipeline.transform(sampled_sparse_matrix1)\n",
    "test = loaded_svd_pipeline.transform(sampled_sparse_matrix2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13a5dfad-def7-411a-864b-326ac6a2f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to get target for this sampled_sparse_matrix\n",
    "target = h5py.File(train_multi_targets,'r')#, mode)\n",
    "target_train = target['train_multi_targets']['block0_values'][first_sample_indices,:]\n",
    "target_test = target['train_multi_targets']['block0_values'][second_sample_indices,:]\n",
    "X = np.concatenate((train,test),axis=0)\n",
    "y = np.concatenate((target_train,target_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d6e60d8-a9c7-44e8-980b-f554e5338315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving X and y to speed up future loads.\n",
    "from numpy import savetxt\n",
    "savetxt('X.csv', X, delimiter=',')\n",
    "savetxt('y.csv', y, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5716f254-9791-4de6-b400-bafd33d1e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load numpy array from csv file\n",
    "from numpy import loadtxt\n",
    "# load array\n",
    "X = loadtxt('X.csv', delimiter=',')\n",
    "y = loadtxt('y.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97355f54-c5e7-4ae5-894a-ccca404f70ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000, 6000) (21000, 23418)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93193d61-0c01-4d33-8f5b-2e747cee4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aa9441d-3508-467a-b01f-54c55ff9065e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'predictor': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = XGBRegressor(n_jobs=-1,tree_method = 'hist', sampling_method='gradient_based',\n",
    "                  max_depth = 10, subsample = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "238e714e-5813-4abd-a1f7-032c21f02b00",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.393 total time=  14.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.307 total time=  14.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.215 total time=  14.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.180 total time=  14.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.102 total time=  14.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.316 total time=  15.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.242 total time=  14.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.171 total time=  14.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.124 total time=  14.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.086 total time=  15.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.274 total time=  14.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.182 total time=  14.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.128 total time=  15.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.068 total time=  14.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.019 total time=  14.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.302 total time=  15.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.252 total time=  15.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.173 total time=  15.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.152 total time=  14.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.087 total time=  14.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.298 total time=  15.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.211 total time=  15.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.197 total time=  15.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.131 total time=  15.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.042 total time=  15.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-2.278 total time=  15.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-2.182 total time=  15.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-2.133 total time=  15.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-2.067 total time=  15.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-2.018 total time=  15.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-2.268 total time=  13.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-2.166 total time=  13.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-2.109 total time=  13.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-2.050 total time=  14.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-1.988 total time=  13.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-2.245 total time=  13.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-2.148 total time=  13.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-2.129 total time=  13.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-2.043 total time=  14.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-1.998 total time=  14.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-2.235 total time=  13.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-2.156 total time=  14.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-2.115 total time=  14.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-2.051 total time=  14.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-1.973 total time=  14.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-3.106 total time=  15.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-3.152 total time=  15.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-2.976 total time=  15.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-2.936 total time=  15.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-3.000 total time=  15.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-3.015 total time=  15.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-2.869 total time=  15.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-2.880 total time=  15.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-2.859 total time=  15.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-2.808 total time=  15.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.751 total time=  15.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.624 total time=  15.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.579 total time=  16.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.515 total time=  15.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.483 total time=  15.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-2.946 total time=  16.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-2.915 total time=  16.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-2.848 total time=  16.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-2.819 total time=  15.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-2.684 total time=  15.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.917 total time=  16.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.841 total time=  16.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.779 total time=  16.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.653 total time=  15.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.648 total time=  15.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.717 total time=  15.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.587 total time=  15.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.558 total time=  16.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.483 total time=  15.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.498 total time=  15.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.618 total time=  12.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.477 total time=  12.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.410 total time=  12.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.370 total time=  12.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.257 total time=  12.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.553 total time=  12.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.475 total time=  12.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.443 total time=  12.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.331 total time=  12.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.251 total time=  12.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.489 total time=  12.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.421 total time=  12.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.345 total time=  12.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.302 total time=  12.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.259 total time=  12.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.417 total time=  15.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.294 total time=  15.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.209 total time=  15.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.170 total time=  15.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.130 total time=  15.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.350 total time=  16.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.242 total time=  16.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.194 total time=  15.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.160 total time=  15.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.060 total time=  16.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.274 total time=  16.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.162 total time=  16.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.135 total time=  16.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.072 total time=  16.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.018 total time=  16.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.366 total time=  16.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.255 total time=  16.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.198 total time=  16.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.150 total time=  16.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.063 total time=  16.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.316 total time=  16.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.215 total time=  16.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.169 total time=  16.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.114 total time=  16.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.074 total time=  16.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-2.280 total time=  16.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-2.157 total time=  16.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-2.121 total time=  16.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-2.079 total time=  16.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-2.005 total time=  16.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-2.249 total time=  14.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-2.159 total time=  14.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-2.100 total time=  14.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-2.048 total time=  15.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-1.988 total time=  15.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-2.258 total time=  14.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-2.165 total time=  14.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-2.106 total time=  14.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-2.039 total time=  14.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-1.993 total time=  14.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-2.258 total time=  14.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-2.157 total time=  15.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-2.122 total time=  15.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-2.040 total time=  15.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-1.993 total time=  15.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-3.229 total time=  17.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-3.040 total time=  16.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-3.047 total time=  16.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-2.973 total time=  16.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-2.898 total time=  16.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-3.065 total time=  17.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-2.931 total time=  17.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-2.868 total time=  16.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-2.893 total time=  16.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-2.732 total time=  17.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.689 total time=  16.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.608 total time=  16.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.594 total time=  17.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.522 total time=  16.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.502 total time=  16.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-3.045 total time=  17.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-2.988 total time=  17.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-2.796 total time=  17.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-2.783 total time=  16.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-2.749 total time=  16.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.933 total time=  16.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.821 total time=  17.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.736 total time=  17.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.696 total time=  16.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.658 total time=  16.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.762 total time=  16.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.678 total time=  16.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.561 total time=  17.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.487 total time=  16.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.456 total time=  17.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.514 total time=  13.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.449 total time=  13.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.403 total time=  13.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.337 total time=  13.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.307 total time=  13.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.507 total time=  13.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.449 total time=  13.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.438 total time=  13.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.337 total time=  13.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.266 total time=  13.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.547 total time=  13.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.376 total time=  13.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.363 total time=  13.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.319 total time=  13.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.290 total time=  13.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.380 total time=  16.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.342 total time=  16.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.248 total time=  16.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.179 total time=  16.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=1;, score=-2.115 total time=  16.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.341 total time=  17.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.269 total time=  17.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.175 total time=  17.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.128 total time=  16.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=5;, score=-2.088 total time=  17.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.263 total time=  17.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.163 total time=  17.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.119 total time=  17.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.075 total time=  17.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=1, reg_lambda=100;, score=-2.012 total time=  17.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.339 total time=  17.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.248 total time=  17.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.196 total time=  17.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.157 total time=  17.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=1;, score=-2.081 total time=  17.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.325 total time=  17.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.226 total time=  17.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.157 total time=  17.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.109 total time=  17.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=5;, score=-2.057 total time=  17.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-2.277 total time=  17.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-2.170 total time=  17.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-2.119 total time=  18.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-2.067 total time=  17.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=5, reg_lambda=100;, score=-1.999 total time=  17.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-2.252 total time=  15.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-2.167 total time=  15.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-2.114 total time=  15.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-2.055 total time=  16.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=1;, score=-1.982 total time=  15.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-2.268 total time=  15.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-2.158 total time=  15.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-2.113 total time=  15.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-2.052 total time=  15.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=5;, score=-1.993 total time=  15.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-2.250 total time=  15.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-2.161 total time=  15.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-2.121 total time=  15.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-2.033 total time=  16.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, reg_alpha=100, reg_lambda=100;, score=-1.990 total time=  16.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-3.207 total time=  18.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-3.167 total time=  18.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-2.962 total time=  17.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-3.033 total time=  18.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=1;, score=-2.908 total time=  17.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-3.080 total time=  18.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-2.903 total time=  18.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-2.879 total time=  18.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-2.834 total time=  17.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=5;, score=-2.780 total time=  18.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.771 total time=  17.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.645 total time=  17.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.600 total time=  18.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.487 total time=  17.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=1, reg_lambda=100;, score=-2.433 total time=  17.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-3.051 total time=  18.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-2.934 total time=  18.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-2.881 total time=  18.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-2.798 total time=  17.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=1;, score=-2.768 total time=  18.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.965 total time=  18.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.866 total time=  18.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.712 total time=  18.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.689 total time=  17.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=5;, score=-2.694 total time=  18.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.662 total time=  18.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.627 total time=  18.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.491 total time=  18.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.479 total time=  18.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=5, reg_lambda=100;, score=-2.473 total time=  18.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.574 total time=  14.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.475 total time=  14.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.428 total time=  14.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.358 total time=  14.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=1;, score=-2.248 total time=  14.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.545 total time=  14.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.478 total time=  14.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.389 total time=  14.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.302 total time=  14.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=5;, score=-2.299 total time=  14.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.580 total time=  14.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.385 total time=  14.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.401 total time=  14.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.299 total time=  14.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.5, reg_alpha=100, reg_lambda=100;, score=-2.222 total time=  14.6s\n",
      "Best parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'reg_alpha': 100, 'reg_lambda': 100}\n",
      "Pearson Error on test set: PearsonRResult(statistic=0.020558562076637768, pvalue=0.1828301930876329)\n",
      "--- 4280.425397157669 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "start_time = time.time()\n",
    "# Create an instance of XGBRegressor\n",
    "xgb_model = XGBRegressor(n_jobs=-1,tree_method=\"gpu_hist\", sampling_method='gradient_based',\n",
    "                        subsample = 0.7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2, random_state=3)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    #'n_estimators': [100, 200, 300],\n",
    "    #'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.1, 0.5],\n",
    "    #'min_child_weight': [1, 3, 5],\n",
    "    #'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [1, 5, 100],\n",
    "    'reg_lambda': [1, 5, 100]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV instance\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           cv=5, scoring='neg_mean_squared_error',verbose = 3)\n",
    "\n",
    "# Fit the GridSearchCV instance on the data\n",
    "grid_search.fit(X_train, y_train[:,0])\n",
    "\n",
    "# Print the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Use the best model to make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error on the test set\n",
    "pe = scipy.stats.pearsonr(y_test[:,0], y_pred)\n",
    "print(\"Pearson Error on test set:\", pe)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad3bbc5-781d-4a2a-befb-ff354fcd69d4",
   "metadata": {},
   "source": [
    "After running this grid search for y -- first column of the target\n",
    "xgb_model = XGBRegressor(n_jobs=-1,tree_method=\"gpu_hist\", sampling_method='gradient_based',\n",
    "                        subsample = 0.7)\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.5],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [1, 5, 100],\n",
    "    'reg_lambda': [1, 5, 100]\n",
    "}\n",
    "I got this parameters as the best:\n",
    "'colsample_bytree': 0.7, 'learning_rate': 0.1, 'reg_alpha': 100, 'reg_lambda': 100\n",
    "But Pearson correlation for this target is only 0.02.\n",
    "So my plan is to run XGBRegressor with this parameters on random sample of columns to choose a column that makes better prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd9fb5-0cbc-4f26-96ef-7cac3e7399ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I just randomly picked a column and XGBRegressor gives much better results,\n",
    "# so I am wandering if there are better targets to run grid search\n",
    "\n",
    "xgb_model = XGBRegressor( \n",
    "    n_jobs=-1,tree_method=\"gpu_hist\", verbosity=2\n",
    "    , subsample = 0.7, colsample_bytree =0.7,learning_rate = 0.09, reg_alpha = 250, reg_lambda = 500, gamma=1,\n",
    "                        min_child_weight=100, sampling_method = 'gradient_based'\n",
    "  )\n",
    "start_time = time.time()\n",
    "xgb_model.fit(X_train, y_train[:,14096],verbose=True)\n",
    "print(sqrt(xgb_model.score(X_train, y_train[:,14096])))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "p1 = xgb_model.predict(X_train)\n",
    "print(scipy.stats.pearsonr(p1, y_train[:,14096]))\n",
    "predicted = xgb_model.predict(X_test)\n",
    "print(scipy.stats.pearsonr(predicted, y_test[:,14096]))\n",
    "#subsample = 0.7, colsample_bytree=0.7, learning_rate=0.09, reg_alpha=100, reg_lambda=100\n",
    "# 0.5229017064868956\n",
    "# --- 12.488898754119873 seconds ---\n",
    "# PearsonRResult(statistic=0.5985726654063924, pvalue=0.0)\n",
    "# PearsonRResult(statistic=0.26056824177488264, pvalue=3.792858971681166e-66)\n",
    "\n",
    "#subsample = 0.7, colsample_bytree=0.7, learning_rate=0.09, reg_alpha=100, reg_lambda=100, max_depth = 7\n",
    "# 0.5385230762815163\n",
    "# --- 14.120773077011108 seconds ---\n",
    "# PearsonRResult(statistic=0.6247811604984794, pvalue=0.0)\n",
    "# PearsonRResult(statistic=0.2617363389312549, pvalue=9.553685119578894e-67)\n",
    "\n",
    "#, subsample = 0.7, colsample_bytree=0.7, learning_rate=0.09, reg_alpha=100, reg_lambda=100, n_estimators = 50\n",
    "# 0.4163106228883361\n",
    "# --- 8.543477773666382 seconds ---\n",
    "# PearsonRResult(statistic=0.4574713824192653, pvalue=0.0)\n",
    "# PearsonRResult(statistic=0.2663462998646093, pvalue=3.864689556613428e-69)\n",
    "\n",
    "\n",
    "# 0.21957893614536603\n",
    "# --- 5.339459419250488 seconds ---\n",
    "# PearsonRResult(statistic=0.2793968777604519, pvalue=7.41405478116927e-299)\n",
    "# PearsonRResult(statistic=0.2577042412127594, pvalue=1.0820165832194626e-64)\n",
    "\n",
    "\n",
    "#, subsample = 0.7, colsample_bytree=0.7, learning_rate=0.09, reg_alpha=500, reg_lambda=500, n_estimators = 100\n",
    "# 0.27475893068348195\n",
    "# --- 7.954516649246216 seconds ---\n",
    "# PearsonRResult(statistic=0.29485697862193605, pvalue=0.0)\n",
    "# PearsonRResult(statistic=0.2666221293470263, pvalue=2.7695770605428915e-69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34d06b1a-6973-471c-8fdf-6daa79a321de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23418"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df5f98c7-ee2c-4496-acf7-da36e6f7248b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skovtun/.local/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBRegressor( \n",
    "    n_jobs=-1,tree_method=\"gpu_hist\", verbosity=2\n",
    "    , subsample = 0.7, colsample_bytree=0.7, learning_rate=0.1, reg_alpha=100, reg_lambda=100\n",
    "  )\n",
    "col_ind = np.random.choice(y_train.shape[1], size=100, replace=False)\n",
    "pearson_test=[]\n",
    "pearson_train=[]\n",
    "for i in col_ind:\n",
    "    xgb_model.fit(X_train, y_train[:,i],verbose=True)\n",
    "    p1 = xgb_model.predict(X_train)\n",
    "    pearson_train.append(scipy.stats.pearsonr(p1, y_train[:,i]))\n",
    "    pearson_test.append(scipy.stats.pearsonr(predicted, y_test[:,i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aeea37ff-53f9-4b8a-8578-d6f76800fd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03658567733575236"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_test[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4f2fda4-de92-49f9-89d4-8651501db70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PearsonRResult(statistic=-0.2109241147973103, pvalue=1.9002299635074363e-43),\n",
       " PearsonRResult(statistic=0.2149082434624963, pvalue=4.474537026947123e-45)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in pearson_test if abs(item[0]) > 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b874a52-2672-4a10-8b95-d7abc9f79d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60, 98]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(length(pearson_test)) if abs(pearson_test[i][0])>0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b526dd04-7f88-4008-82a1-2a01b34e0aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.6701438622520924, pvalue=0.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_train[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54cf96ac-e277-446b-9a9d-60cfd8e9f8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10042"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_ind[98]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14196e08-98a2-41f7-b7fd-05acbaae51d7",
   "metadata": {},
   "source": [
    "We didn't get better result than my randomly picked column, so I am running grid search on it,\n",
    "keeping in mind, that we are going to test it on 10133 and 10042 columns.\n",
    "Test results:\n",
    "[PearsonRResult(statistic=-0.2109241147973103, pvalue=1.9002299635074363e-43),\n",
    " PearsonRResult(statistic=0.2149082434624963, pvalue=4.474537026947123e-45)]\n",
    "Train results: \n",
    "PearsonRResult(statistic=0.6835967167220898, pvalue=0.0)\n",
    "PearsonRResult(statistic=0.6701438622520924, pvalue=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6778dc38-e6c5-4927-9b63-b34eea10ecf3",
   "metadata": {},
   "source": [
    "xgb_model = XGBRegressor(n_jobs=-1,tree_method=\"gpu_hist\", sampling_method='gradient_based',\n",
    "                        subsample = 0.7, colsample_bytree =0.7 )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2, random_state=3)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [30, 50, 100],\n",
    "    #'max_depth': [3, 7, 9],\n",
    "    'learning_rate': [0.09, 0.1],\n",
    "    #'min_child_weight': [1, 3, 5],\n",
    "    #'subsample': [0.7, 0.8, 0.9],\n",
    "    #'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [80, 100, 250,500],\n",
    "    'reg_lambda': [80, 100, 250,500]\n",
    "}\n",
    "\n",
    "Best parameters: {'learning_rate': 0.09, 'n_estimators': 100, 'reg_alpha': 250, 'reg_lambda': 500}\n",
    "\n",
    "\n",
    "xgb_model = XGBRegressor(n_jobs=-1,tree_method=\"gpu_hist\", sampling_method='gradient_based',\n",
    "                        subsample = 0.7, colsample_bytree =0.7,learning_rate = 0.09, reg_alpha = 250, reg_lambda = 500, gamma = 1 )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2, random_state=3)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'gamma' : [0.1, 1, 10, 50, 100, 500]\n",
    "    \n",
    "}\n",
    "Best parameters: {'gamma': 0.1}\n",
    "Pearson Error on test set: PearsonRResult(statistic=0.25832934954319725, pvalue=5.225897103493157e-65)\n",
    "--- 175.74791884422302 seconds ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a5c06c-b406-42a2-a6d1-318e9fdf21de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END .............min_child_weight=0.1;, score=-0.982 total time=   6.2s\n",
      "[CV 2/5] END .............min_child_weight=0.1;, score=-0.833 total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x7f2406301b70>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skovtun/.local/lib/python3.10/site-packages/xgboost/core.py\", line 500, in _next_wrapper\n",
      "    def _next_wrapper(self, this: None) -> int:  # pylint: disable=unused-argument\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "start_time = time.time()\n",
    "# Create an instance of XGBRegressor\n",
    "xgb_model = XGBRegressor(n_jobs=-1,tree_method=\"gpu_hist\", sampling_method='gradient_based',\n",
    "                        subsample = 0.7, colsample_bytree =0.7,learning_rate = 0.09, reg_alpha = 250, reg_lambda = 500, gamma=1,\n",
    "                        min_child_weight=100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2, random_state=3)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    #'n_estimators': [30, 50, 100],\n",
    "    #'max_depth': [3, 7, 9],\n",
    "    #'learning_rate': [0.09, 0.1],\n",
    "    #'min_child_weight': [1, 3, 5],\n",
    "    #'subsample': [0.7, 0.8, 0.9],\n",
    "    #'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    #'reg_alpha': [80, 100, 250,500],\n",
    "    #'reg_lambda': [80, 100, 250,500]\n",
    "    #'gamma' : [0.1, 1, 10, 50, 100, 500]\n",
    "    'min_child_weight':[0.1, 1, 10, 50, 100, 500]\n",
    "    \n",
    "}\n",
    "\n",
    "# Create a GridSearchCV instance\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           cv=5, scoring='neg_mean_squared_error',verbose = 3)\n",
    "\n",
    "# Fit the GridSearchCV instance on the data\n",
    "grid_search.fit(X_train, y_train[:,14096])\n",
    "\n",
    "# Print the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Use the best model to make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error on the test set\n",
    "pe = scipy.stats.pearsonr(y_test[:,14096], y_pred)\n",
    "print(\"Pearson Error on test set:\", pe)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in days:\n",
    "    for donor in donors:\n",
    "        name = 'donor'+str(donor)+'day'+str(day)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93876e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105942 9558\n",
      "9558\n",
      "9558\n",
      "9558\n",
      "(9558, 228942)\n",
      "8752910672\n",
      "194338.32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<9558x222226 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 48584580 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donor1_day_1=[i.encode('UTF-8') \n",
    "              for i in mult['cell_id'].loc[(mult['donor'] == 13176) & (mult['day'] == 2)]\n",
    "             ]\n",
    "Xm_train_axis1 = np.array(Xm_train['train_multi_inputs']['axis1']).tolist()\n",
    "print(len(Xm_train_axis1), len(donor1_day_1))\n",
    "both = set(Xm_train_axis1).intersection(donor1_day_1)\n",
    "print(len(both))\n",
    "indices_A = [Xm_train_axis1.index(x) for x in both]\n",
    "print(len(indices_A))\n",
    "indices_A.sort()\n",
    "print(len(indices_A))\n",
    "train_donor1_day_1 = Xm_train['train_multi_inputs']['block0_values'][indices_A,:]\n",
    "train_donor1_day_1_sparse = scipy.sparse.csr_matrix(train_donor1_day_1)\n",
    "print(train_donor1_day_1.shape)\n",
    "print(getsizeof(train_donor1_day_1))\n",
    "print(train_donor1_day_1_sparse.data.nbytes/1000)\n",
    "columns_to_delete = np.nonzero(1-np.ones(train_donor1_day_1_sparse.shape[0],dtype=bool)*train_donor1_day_1_sparse.astype(bool))[0].tolist()\n",
    "all_columns = [i for i in range(0, train_donor1_day_1_sparse.shape[1])]\n",
    "to_keep = [x for x in all_columns if x not in columns_to_delete]\n",
    "train_donor1_day_1_sparse.tocsc()[:,to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42976d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So right now I am stuck with the issue of having 9500 observations and 222 thousands of features. \n",
    "#Should I use PCA and reduce number of features? For PCA what is number of features to leave?\n",
    "#Should I train several XGBoost models on different columns and then stack them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "846bf6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = h5py.File(train_multi_targets,'r')#, mode)\n",
    "target_train_donor1_day_1 = target['train_multi_targets']['block0_values'][indices_A,:]\n",
    "#train_donor1_day_1_sparse = scipy.sparse.csr_matrix(train_donor1_day_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0091004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9558, 23418)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train_donor1_day_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1dd01731",
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = target_train_donor1_day_1[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd56d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try to train one model to access the speed:\n",
    "xgb_model = XGBRegressor( n_jobs=6)\n",
    "start_time = time.time()\n",
    "xgb_model.fit(train_donor1_day_1_sparse, target1)\n",
    "print(sqrt(xgb_model.score(train_donor1_day_1_sparse, target1)))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e22b190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8996748346558805"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "sqrt(xgb_model.score(train_donor1_day_1_sparse, target1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07f52491",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importances_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_donor1_day_1_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget1\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "xgb_model.feature_importances_(train_donor1_day_1_sparse, target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6612e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "816.098611111111"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.9970743244982367 #--- 502.8824908733368 seconds --- for 10 targets\n",
    "2341*502/60/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b6039a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So at firs I will read only small portion of the data to test this approach.\n",
    "ex = pd.DataFrame(Xm_train['train_multi_inputs']['block0_values'][:600,:500])\n",
    "ex_sparse = scipy.sparse.csr_matrix(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e42087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<600x452 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 9475 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_delete = np.nonzero(1 - np.ones(ex_sparse.shape[0],dtype=bool)*ex_sparse.astype(bool))[0].tolist()\n",
    "all_columns = [i for i in range(0, ex_sparse.shape[1])]\n",
    "to_keep = [x for x in all_columns if x not in columns_to_delete]\n",
    "ex_sparse.tocsc()[:,to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4035c6c-daf3-4ac9-9e14-57142413dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so, I got 35 features that are highly correlated. I am not sure I want to implement\n",
    "# for a big matrix???\n",
    "import numpy as np    \n",
    "def sparse_corr(A):\n",
    "    N = A.shape[0]\n",
    "    C=((A.T*A -(sum(A).T*sum(A)/N))/(N-1)).todense()\n",
    "    V=np.sqrt(np.mat(np.diag(C)).T*np.mat(np.diag(C)))\n",
    "    COR = np.divide(C,V+1e-119)\n",
    "    return COR\n",
    "#So this code didn't work, not enogh memory for the bigger matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccfa2c5-e365-4dc2-813e-dd7749a3f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import MiniBatchSparsePCA\n",
    "start_time = time.time()\n",
    "pca = MiniBatchSparsePCA(n_components=100, n_jobs=-1)\n",
    "pca_result = pca.fit_transform(train_donor1_day_1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#PCA will not work, because the result would not be a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "865419e9-c8ac-4e73-935f-514ddde400f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 29067.300805330276 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1791.4833333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "start_time = time.time()\n",
    "svd = TruncatedSVD(n_components=9000, n_iter=7, random_state=42)\n",
    "svd.fit(train_donor1_day_1_sparse)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# 100 components explained  0.019061912\n",
    "# 3000 0.4102357\n",
    "# 9000 0.9663964"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d14c4-e683-477f-9cd7-4acf4a7917db",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "svd = TruncatedSVD(n_components=9000, n_iter=7, random_state=42)\n",
    "svd.fit(train_donor1_day_1_sparse)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# 100 components explained  0.019061912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "165ebb21-996c-4d06-b6fa-bf18595ee8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7163671e-03 1.1904377e-03 7.0503086e-04 ... 5.8951173e-05 5.8914320e-05\n",
      " 5.8865757e-05]\n",
      "0.9663964\n",
      "[3606.6575   657.63556  506.14157 ...  146.34319  146.29845  146.23705]\n"
     ]
    }
   ],
   "source": [
    "print(svd.explained_variance_ratio_)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "print(svd.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dc02996-f9bb-415f-a158-f28fc755c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(svd, open('svd_donor1_day1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9744a5e8-33db-452a-b56b-d142166fe115",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_donor1_day_1_reduced = svd.transform(train_donor1_day_1_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2a97c26-e434-42f0-af61-33ff34b4dc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9558, 9000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_donor1_day_1_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b22b6a2f-0ee9-4592-82dd-03c604b1ca2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:16:34] WARNING: ../src/learner.cc:339: No visible GPU is found, setting `gpu_id` to -1\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[14:16:34] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.\nStack trace:\n  [bt] (0) /home/skovtun/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2a7e13) [0x7ff81aca7e13]\n  [bt] (1) /home/skovtun/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2ab120) [0x7ff81acab120]\n  [bt] (2) /home/skovtun/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2ab52a) [0x7ff81acab52a]\n  [bt] (3) /home/skovtun/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2e03c7) [0x7ff81ace03c7]\n  [bt] (4) /home/skovtun/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7ff81ab3c5a0]\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7ff88acb5e2e]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7ff88acb2493]\n  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7ff88acc53e9]\n  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x7ff88acc4a00]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBRegressor( n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_donor1_day_1_reduced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(sqrt(xgb_model\u001b[38;5;241m.\u001b[39mscore(train_donor1_day_1_reduced, target1)))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds ---\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m (\n\u001b[1;32m   1017\u001b[0m     model,\n\u001b[1;32m   1018\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1024\u001b[0m )\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [14:16:34] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.\nStack trace:\n  [bt] (0) /home/skovtun/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2a7e13) [0x7ff81aca7e13]\n  [bt] (1) /home/skovtun/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2ab120) [0x7ff81acab120]\n  [bt] (2) /home/skovtun/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2ab52a) [0x7ff81acab52a]\n  [bt] (3) /home/skovtun/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2e03c7) [0x7ff81ace03c7]\n  [bt] (4) /home/skovtun/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7ff81ab3c5a0]\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7ff88acb5e2e]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7ff88acb2493]\n  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7ff88acc53e9]\n  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x7ff88acc4a00]\n\n"
     ]
    }
   ],
   "source": [
    "target1 = target_train_donor1_day_1[:, 0]\n",
    "xgb_model = XGBRegressor( n_jobs=6,tree_method=\"gpu_hist\")\n",
    "start_time = time.time()\n",
    "xgb_model.fit(train_donor1_day_1_reduced, target1)\n",
    "print(sqrt(xgb_model.score(train_donor1_day_1_reduced, target1)))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdf6bae2-f624-476f-9f2c-aa78d30ef641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74852be0-de4e-4eb9-a0db-17646f9f41f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9263854134839254\n"
     ]
    }
   ],
   "source": [
    "print(sqrt(xgb_model.score(train_donor1_day_1_reduced, target1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "004eb3d9-0d7f-4fd4-83a8-c36c5ac9ed7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105942 7089\n",
      "7089\n",
      "7089\n",
      "7089\n",
      "(7089, 228942)\n",
      "6491879480\n",
      "136554.064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<7089x222226 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 34086935 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's apply obtained svd to donors 2 (31800) and 3 (32606) for the first day.\n",
    "donor2_day_1=[i.encode('UTF-8') \n",
    "              for i in mult['cell_id'].loc[(mult['donor'] == 31800) & (mult['day'] == 2)]\n",
    "             ]\n",
    "Xm_train_axis1 = np.array(Xm_train['train_multi_inputs']['axis1']).tolist()\n",
    "print(len(Xm_train_axis1), len(donor2_day_1))\n",
    "both = set(Xm_train_axis1).intersection(donor2_day_1)\n",
    "print(len(both))\n",
    "indices_A = [Xm_train_axis1.index(x) for x in both]\n",
    "print(len(indices_A))\n",
    "indices_A.sort()\n",
    "print(len(indices_A))\n",
    "train_donor2_day_1 = Xm_train['train_multi_inputs']['block0_values'][indices_A,:]\n",
    "train_donor2_day_1_sparse = scipy.sparse.csr_matrix(train_donor2_day_1)\n",
    "target_train_donor2_day_1 = target['train_multi_targets']['block0_values'][indices_A,:]\n",
    "print(train_donor2_day_1.shape)\n",
    "print(getsizeof(train_donor2_day_1))\n",
    "print(train_donor2_day_1_sparse.data.nbytes/1000)\n",
    "#columns_to_delete = np.nonzero(1-np.ones(train_donor1_day_1_sparse.shape[0],dtype=bool)*train_donor1_day_1_sparse.astype(bool))[0].tolist()\n",
    "#all_columns = [i for i in range(0, train_donor1_day_1_sparse.shape[1])]\n",
    "#to_keep = [x for x in all_columns if x not in columns_to_delete]\n",
    "train_donor2_day_1_sparse.tocsc()[:,to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71396f42-40da-4cfe-982c-82e119ea88c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105942 7264\n",
      "7264\n",
      "7264\n",
      "7264\n",
      "(7264, 228942)\n",
      "6652138880\n",
      "136554.064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<7264x222226 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 35296481 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's apply obtained svd to donors 2 (31800) and 3 (32606) for the first day.\n",
    "donor3_day_1=[i.encode('UTF-8') \n",
    "              for i in mult['cell_id'].loc[(mult['donor'] == 32606) & (mult['day'] == 2)]\n",
    "             ]\n",
    "Xm_train_axis1 = np.array(Xm_train['train_multi_inputs']['axis1']).tolist()\n",
    "print(len(Xm_train_axis1), len(donor3_day_1))\n",
    "both = set(Xm_train_axis1).intersection(donor3_day_1)\n",
    "print(len(both))\n",
    "indices_A = [Xm_train_axis1.index(x) for x in both]\n",
    "print(len(indices_A))\n",
    "indices_A.sort()\n",
    "print(len(indices_A))\n",
    "train_donor3_day_1 = Xm_train['train_multi_inputs']['block0_values'][indices_A,:]\n",
    "train_donor3_day_1_sparse = scipy.sparse.csr_matrix(train_donor3_day_1)\n",
    "target_train_donor3_day_1 = target['train_multi_targets']['block0_values'][indices_A,:]\n",
    "print(train_donor3_day_1.shape)\n",
    "print(getsizeof(train_donor3_day_1))\n",
    "print(train_donor2_day_1_sparse.data.nbytes/1000)\n",
    "#columns_to_delete = np.nonzero(1-np.ones(train_donor1_day_1_sparse.shape[0],dtype=bool)*train_donor1_day_1_sparse.astype(bool))[0].tolist()\n",
    "#all_columns = [i for i in range(0, train_donor1_day_1_sparse.shape[1])]\n",
    "#to_keep = [x for x in all_columns if x not in columns_to_delete]\n",
    "train_donor3_day_1_sparse.tocsc()[:,to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3189c9d6-e64c-40fa-87bb-ea89573727c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7089, 9000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_donor3_day_1_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c376f83-dd25-4d72-bccd-f5bd2ea26133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD transform--- 227.78802132606506 seconds ---\n",
      "0.9801431112615508\n",
      "XGBRegressor--- 402.30550837516785 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train_donor2_day_1_reduced = svd.transform(train_donor2_day_1_sparse)\n",
    "print(\"SVD transform--- %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "target1 = target_train_donor2_day_1[:, 0]\n",
    "xgb_model2 = XGBRegressor( n_jobs=6)\n",
    "xgb_model2.fit(train_donor2_day_1_reduced, target1)\n",
    "print(sqrt(xgb_model2.score(train_donor2_day_1_reduced, target1)))\n",
    "print(\"XGBRegressor--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4dc70ee-e254-4469-8afb-aceeba1fba0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD transform--- 238.20122361183167 seconds ---\n",
      "0.9799085317356196\n",
      "XGBRegressor--- 392.57107043266296 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train_donor3_day_1_reduced = svd.transform(train_donor3_day_1_sparse)\n",
    "print(\"SVD transform--- %s seconds ---\" % (time.time() - start_time))\n",
    "xgb_model3 = XGBRegressor( n_jobs=6)\n",
    "target1 = target_train_donor3_day_1[:, 0]\n",
    "start_time = time.time()\n",
    "xgb_model3.fit(train_donor3_day_1_reduced, target1)\n",
    "print(sqrt(xgb_model3.score(train_donor3_day_1_reduced, target1)))\n",
    "print(\"XGBRegressor--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eaf3c3-8934-4161-87ea-66a77fb263cc",
   "metadata": {},
   "source": [
    "# Why there is no donor 2 in day 2 multiome?\n",
    "#let's take all cell_id from multiome and see what phenotype data is available for them.\n",
    "cell_id_xm_test = [i.decode('UTF-8') for i in Xm_test_axis1]\n",
    "xm_test_mult = mult[mult['cell_id'].isin(cell_id_xm_test)]\n",
    "# Looking at ways to split multiome data into chunks\n",
    "mt = xm_test_mult.groupby(['day','donor']).aggregate({'cell_type':'count'})\n",
    "print(mt)\n",
    "      cell_type\n",
    "day donor           \n",
    "2   27678       8921\n",
    "3   27678       7950\n",
    "7   27678       7291\n",
    "10  13176       8421\n",
    "    27678       8790\n",
    "    31800       7144\n",
    "    32606       7418\n",
    "# Answer: donor that I thought was donor 2 is actually donor 4 :) So these cells are in test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cfa63f-1ee9-4eae-8274-ba5adff33343",
   "metadata": {},
   "source": [
    "# So right now we have 3 models, let's:\n",
    "1. Access every model on donor 4\n",
    "2. Apply average of this model on donor 4\n",
    "3. Build one model on using combining 3 sparse reduced datasets\n",
    "4. Access donor 4 on this model.\n",
    "# Ok, there is no targets for donor4, test dataset is for submission only.\n",
    "# There are 23418 target values!!! How I am going to calculate all of them.\n",
    "# My one target models works ~7 minutes. I need to find a way to run XGBRegressor faster without\n",
    "# conslderable loss in quality.\n",
    "# How about we split train/test sample and check if it is just overfitting.\n",
    "# My plan is:\n",
    "# combine all 3 reduced datasets from donors 1-3, make a split to train/test sets\n",
    "#  check for overfitting.\n",
    "# experiment with XGBRegressor's parameters to make it faster and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef506c2f-5299-41ff-a8e4-41a320182d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_day1 = np.concatenate((train_donor1_day_1_reduced, train_donor2_day_1_reduced,train_donor3_day_1_reduced), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b662894-205c-4f87-8ad5-3f01bd30cf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23911, 9000)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_day1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b782a5db-e274-4726-bf52-9024643d6e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23911,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = target_train_donor1_day_1[:, 0]\n",
    "t2 = target_train_donor2_day_1[:, 0]\n",
    "t3 = target_train_donor3_day_1[:, 0]\n",
    "target_1 = np.concatenate((t1,t2,t3), axis=0)\n",
    "target_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ac6c61ab-4533-4032-9551-bed9d7d8c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_day1, target_1, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5ce331b0-74d0-42a7-bbd7-f2ce8f43e87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9764566651408487\n",
      "XGBRegressor--- 954.9350183010101 seconds ---\n"
     ]
    }
   ],
   "source": [
    "xgb_model_day1 = XGBRegressor( n_jobs=6)\n",
    "start_time = time.time()\n",
    "xgb_model_day1.fit(X_train, y_train)\n",
    "print(sqrt(xgb_model_day1.score(X_train, y_train)))\n",
    "print(\"XGBRegressor--- %s seconds ---\" % (time.time() - start_time))\n",
    "#PearsonRResult(statistic=0.9835515716755641, pvalue=0.0)\n",
    "#PearsonRResult(statistic=0.01859062439837992, pvalue=0.09867520519995195)\n",
    "# Overfitted model\n",
    "# reg_alpha=10 no improvement in time\n",
    "# \n",
    "#PearsonRResult(statistic=0.9837345766999173, pvalue=0.0)\n",
    "#PearsonRResult(statistic=0.025935007226085462, pvalue=0.02123033848850604)\n",
    "#reg_alpha=10, reg_lambda = 10\n",
    "#PearsonRResult(statistic=0.9916028693341321, pvalue=0.0)\n",
    "#PearsonRResult(statistic=0.01158868662660165, pvalue=0.20513470929835176)\n",
    "#reg_alpha=50, reg_lambda = 50\n",
    "#PearsonRResult(statistic=0.969035260835841, pvalue=0.0)\n",
    "#PearsonRResult(statistic=-0.00398647417835119, pvalue=0.6629447094477752)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "847aa976-2561-4488-a313-21b0a543d9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9217274834765083\n",
      "XGBRegressor--- 719.4877290725708 seconds ---\n"
     ]
    }
   ],
   "source": [
    "xgb_model_day1 = XGBRegressor( n_jobs=6,reg_alpha=50, reg_lambda = 50,max_depth = )\n",
    "start_time = time.time()\n",
    "xgb_model_day1.fit(X_train, y_train)\n",
    "print(sqrt(xgb_model_day1.score(X_train, y_train)))\n",
    "print(\"XGBRegressor--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ad190abc-31ab-40f0-aabe-262cfd48457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=0.969035260835841, pvalue=0.0)\n",
      "PearsonRResult(statistic=-0.00398647417835119, pvalue=0.6629447094477752)\n"
     ]
    }
   ],
   "source": [
    "p1 = xgb_model_day1.predict(X_train)\n",
    "print(scipy.stats.pearsonr(p1, y_train))\n",
    "predicted = xgb_model_day1.predict(X_test)\n",
    "print(scipy.stats.pearsonr(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dc6864a0-6e8f-463c-be90-26dab7bcf6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8699617063802867\n",
      "XGBRegressor--- 178.0878622531891 seconds ---\n",
      "PearsonRResult(statistic=0.8699617029071725, pvalue=0.0)\n",
      "PearsonRResult(statistic=0.004624152734029992, pvalue=0.6131579417614377)\n"
     ]
    }
   ],
   "source": [
    "ml = LinearRegression(n_jobs=-1)\n",
    "start_time = time.time()\n",
    "ml.fit(X_train, y_train)\n",
    "print(sqrt(ml.score(X_train, y_train)))\n",
    "print(\"XGBRegressor--- %s seconds ---\" % (time.time() - start_time))\n",
    "p1 = ml.predict(X_train)\n",
    "print(scipy.stats.pearsonr(p1, y_train))\n",
    "predicted = ml.predict(X_test)\n",
    "print(scipy.stats.pearsonr(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "55c139bd-22ed-488c-997e-7f3d067457ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 32832\n",
      "8921\n",
      "8921\n",
      "8921\n"
     ]
    }
   ],
   "source": [
    "# preparing test sample: all cells from day 2\n",
    "Xm_test = h5py.File(test_multi_inputs, 'r')\n",
    "day_1=[i.encode('UTF-8') for i in mult['cell_id'].loc[mult['day'] == 2] ]\n",
    "Xm_test_axis1 = np.array(Xm_test['test_multi_inputs']['axis1']).tolist()\n",
    "print(len(Xm_test_axis), len(day_1))\n",
    "both = set(Xm_test_axis1).intersection(day_1)\n",
    "print(len(both))\n",
    "indices_A = [Xm_test_axis1.index(x) for x in both]\n",
    "print(len(indices_A))\n",
    "indices_A.sort()\n",
    "print(len(indices_A))\n",
    "test_day_1 = Xm_test['test_multi_inputs']['block0_values'][indices_A,:]\n",
    "test_day_1_sparse = scipy.sparse.csr_matrix(test_day_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb9e4d2-3c95-4959-b917-9bb666902e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd165b48-d8f6-4238-8046-9011883ba5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8921, 228942)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_day_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ae784da-9638-4530-9c0b-c6b4362cafc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['test_multi_inputs']>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(Xm_test.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d2a40599-35f2-46f1-bd50-6ac116ae0d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'GL000194.1:114519-115365' b'GL000194.1:55758-56597'\n",
      " b'GL000194.1:58217-58957' b'GL000194.1:59535-60431'\n",
      " b'GL000195.1:119766-120427']\n"
     ]
    }
   ],
   "source": [
    "print( Xm_test['test_multi_inputs']['axis0'][:5] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "783e7e59-7002-4826-b7ca-884b6c2c80b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'GL000194.1:114519-115365' b'GL000194.1:55758-56597'\n",
      " b'GL000194.1:58217-58957' ... b'chrY:7729854-7730772'\n",
      " b'chrY:7731785-7732664' b'chrY:7810142-7811040']\n"
     ]
    }
   ],
   "source": [
    "print( Xm_test['test_multi_inputs']['axis0'][:-5] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dbbad47d-4003-4770-9165-cb1dee6552c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtarget_train_donor2_day_1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_multi_targets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxis0\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "target_train_donor2_day_1['train_multi_targets']['axis0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "695241ac-c487-499c-92fd-26b293119f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7568333672718021\n",
      "--- 230.8553318977356 seconds ---\n"
     ]
    }
   ],
   "source": [
    "steps = [('standard_scaler', StandardScaler(with_mean=True)),\n",
    "         ('classifier', LinearRegression(n_jobs=-1))]\n",
    "pipe=Pipeline(steps)\n",
    "start_time = time.time()\n",
    "pipe.fit(X_train,y_train)\n",
    "print(pipe.score(X_train, y_train))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4ceedaea-9a79-411e-8bdd-0a14161cab0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=0.8699617008529998, pvalue=0.0)\n",
      "PearsonRResult(statistic=0.004623799171962471, pvalue=0.6131850849729209)\n"
     ]
    }
   ],
   "source": [
    "p1 = pipe.predict(X_train)\n",
    "print(scipy.stats.pearsonr(p1, y_train))\n",
    "predicted = pipe.predict(X_test)\n",
    "print(scipy.stats.pearsonr(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35fcdfc-e44d-4ca2-8dc9-7e7918564d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
